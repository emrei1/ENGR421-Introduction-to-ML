# -*- coding: utf-8 -*-
"""ENGR421HW7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sgjrIFwn8A6sHwq-u9eqf1vueN5k2I87
"""

# import packages
import numpy as np
import matplotlib.pyplot as plt
from scipy import spatial
import pandas as pd

# import data
data_set_X = np.genfromtxt("hw07_data_set_images.csv", delimiter = ",")
data_set_y = np.genfromtxt("hw07_data_set_labels.csv", delimiter = ",")

split_location = 2000

train_set_X = data_set_X[0:split_location, :]
train_set_y = data_set_y[0:split_location]
test_set_X = data_set_X[split_location : len(data_set_X), :]
test_set_y = data_set_y[split_location : len(data_set_y)]

# retrieve relevant statistics
K = int(np.amax(data_set_y))

means_array = []

for i in range(K + 1):
  this_class = []
  for j in range(len(train_set_X)):
    if i == train_set_y[j]:
      this_class.append(train_set_X[j, :])
  if i != 0:
    this_class = np.array(this_class)
    mean = this_class.mean(0)
    means_array.append(mean)
  
overall_mean = train_set_X.mean(0)

# Calculate SW and SB matrices
SW = 0
for i in range(len(train_set_y)):
  for j in range(K):
    if (j + 1) == train_set_y[i]:
      xi = train_set_X[i, :]
      mj = means_array[j]
      # in this case the transpose variable represents the D x 1 vector
      difference = np.array([xi - mj])
      difference_transpose = difference.T
      SW += np.matmul(difference_transpose, difference)

SB = 0
for i in range(len(train_set_y)):
  for j in range(K):
    if (j + 1) == train_set_y[i]:
      mj = means_array[j]
      # in this case the transpose variable represents the D x 1 vector
      difference = np.array([mj - overall_mean])
      difference_transpose = difference.T
      SB += np.matmul(difference_transpose, difference)

print(SW[0:4, 0:4])
print(SB[0:4, 0:4])

# retrieve the eigenvectors and eigenvalues
SW_inverse = np.linalg.inv(SW)
SW_inv_times_SB = np.matmul(SW_inverse, SB)

eigenvalues, eigenvectors = np.linalg.eig(SW_inv_times_SB)
eigenvalues = eigenvalues.real
eigenvectors = eigenvectors.real

print(eigenvalues[0:9])

# project thetraining and test data points in a two-dimensional subspace
# using the two eigenvectors that correspond to the largest two eigenvalues

first_two_eigenvectors = eigenvectors[:,[0, 1]].T

point_colors = np.array(["#1f78b4", "#33a02c", "#e31a1c", "#ff7f00", "#6a3d9a", "#a6cee3", "#b2df8a", "#fb9a99", "#fdbf6f", "#cab2d6"])
labels = ["t-shirt/top", "trouser", "pullover", "dress", "coat", "sandal", "shirt", "sneaker", "bag", "ankle boot"]


# plot training data points
plt.figure(figsize = (8, 8))
plt.xlim(-6, 6)
plt.ylim(-6, 6)
for j in range(K):
  train_component_one_values = []
  train_component_two_values = []
  for i in range(len(train_set_y)):
    if train_set_y[i] == (j + 1):
      xi = train_set_X[i, :]
      xi_minus_mean = np.array(xi - overall_mean).T
      zi = np.matmul(first_two_eigenvectors, xi_minus_mean)
      train_component_one_values.append(zi[0])
      train_component_two_values.append(zi[1])
  plt.plot(train_component_one_values, train_component_two_values, marker = 'o', linestyle = "none", color = point_colors[j], markersize = 4, label = labels[j])
plt.xlabel("Component#1")
plt.ylabel("Component#2")
plt.legend()

# plot testing data points
plt.figure(figsize = (8, 8))
plt.xlim(-6, 6)
plt.ylim(-6, 6)
for j in range(K):
  test_component_one_values = []
  test_component_two_values = []
  for i in range(len(test_set_y)):
    if test_set_y[i] == (j + 1):
      xi = test_set_X[i, :]
      xi_minus_mean = np.array(xi - overall_mean).T
      zi = np.matmul(first_two_eigenvectors, xi_minus_mean)
      test_component_one_values.append(zi[0])
      test_component_two_values.append(zi[1])
  plt.plot(test_component_one_values, test_component_two_values, marker = 'o', linestyle = "none", color = point_colors[j], markersize = 4, label = labels[j])
plt.xlabel("Component#1")
plt.ylabel("Component#2")
plt.legend()

# print confusion matrix for subspace from largest 9 eigenvalues for train data
first_nine_eigenvectors = eigenvectors[:,[0, 1, 2, 3, 4, 5, 6, 7, 8]].T

z_matrix_train = []

for i in range(len(train_set_X)):
  xi = train_set_X[i, :]
  xi_minus_mean = np.array(xi - overall_mean).T
  zi = np.matmul(first_nine_eigenvectors, xi_minus_mean)
  z_matrix_train.append(zi)

z_matrix_train = np.array(z_matrix_train)
distances_z_train = spatial.distance.cdist(z_matrix_train, z_matrix_train)

k = 11
score = np.zeros((len(train_set_X), K))

for c in range(K):
  score[:, c] = np.asarray([np.sum(train_set_y[np.argsort(distances_z_train[x, :])[range(k)]] == (c + 1)) for x in range(len(train_set_X))]) / k

y_predicted_train = []

for row in score:
  index = np.argmax(row)
  for c in range(K):
    if c == index:
      y_predicted_train.append(index + 1)

confusion_matrix_train = pd.crosstab(np.reshape(y_predicted_train, len(train_set_X)), train_set_y,
                               rownames = ["y_predicted"], colnames = ["y_train"])

print(confusion_matrix_train)

# print confusion matrix for subspace from largest 9 eigenvalues for test data
z_matrix_test = []

for i in range(len(train_set_X)):
  xi = test_set_X[i, :]
  xi_minus_mean = np.array(xi - overall_mean).T
  zi = np.matmul(first_nine_eigenvectors, xi_minus_mean)
  z_matrix_test.append(zi)

z_matrix_test = np.array(z_matrix_test)
distances_z_test = spatial.distance.cdist(z_matrix_test, z_matrix_test)

k = 11
score = np.zeros((len(test_set_X), K))

for c in range(K):
  score[:, c] = np.asarray([np.sum(test_set_y[np.argsort(distances_z_test[x, :])[range(k)]] == (c + 1)) for x in range(len(test_set_X))]) / k

y_predicted_test = []

for row in score:
  index = np.argmax(row)
  for c in range(K):
    if c == index:
      y_predicted_test.append(index + 1)

confusion_matrix_test = pd.crosstab(np.reshape(y_predicted_test, len(test_set_X)), test_set_y,
                               rownames = ["y_predicted"], colnames = ["y_test"])

print(confusion_matrix_test)